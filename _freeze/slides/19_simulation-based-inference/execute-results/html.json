{
  "hash": "d6ced612be1a0bd0f9a8966042dff3c4",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"MATH167R: Simulation based inference\"\nauthor: \"Peter Gao\"\nformat: \n  revealjs:\n    theme: [./slides.scss, ../theme.scss]\neditor: visual\n---\n\n\n\n## Overview of today\n\n-   Sampling distributions\n-   Bootstrap distributions\n\n## Sampling distributions\n\nWithout explicitly saying so, we have been simulating sampling distributions during our simulations.\n\nRecall: A sampling distribution is the probability distribution of a sample-based statistic.\n\nExample: If $X_1,\\ldots, X_{100}$ are iid random variables with variance $1$, what is the distribution of the sample mean $\\overline{X}$?\n\n## Simulating a sampling distribution\n\nExample simulation: Suppose $X_1,\\ldots, X_{100}\\sim N(0,1)$.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\nXbar <- replicate(10000, mean(rnorm(100)))\nhist(Xbar, main = \"Sampling distribution of mean of 100 N(0, 1) variables\")\n```\n\n::: {.cell-output-display}\n![](19_simulation-based-inference_files/figure-revealjs/sample_mean-1.png){fig-alt='Histogram of sampling distribution of mean of 100 normal variables with mean 0 and standard deviation 1 with frequency on the vertical axis and Xbar on the horizontal axis.' width=960}\n:::\n:::\n\n\n\n## Simulating a sampling distribution\n\nWhat if $X_1,\\ldots, X_{100}\\sim \\mathrm{Exp}(1)$?\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\nXbar <- replicate(10000, mean(rexp(100, rate = 1)))\nhist(Xbar, main = \"Sampling distribution of mean of 100 Exponential(1) variables\")\n```\n\n::: {.cell-output-display}\n![](19_simulation-based-inference_files/figure-revealjs/sample_mean_exp-1.png){fig-alt='Histogram of sampling distribution of mean of 100 exponential variables with parameter 1 with frequency on the vertical axis and Xbar on the horizontal axis.' width=960}\n:::\n:::\n\n\n\n## Simulating a sampling distribution\n\nWhat if $X_1,\\ldots, X_{100}\\sim \\mathrm{Poisson}(1)$?\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\nXbar <- replicate(10000, mean(rpois(100, lambda = 1)))\nhist(Xbar, main = \"Sampling distribution of mean of 100 Poisson(1) variables\")\n```\n\n::: {.cell-output-display}\n![](19_simulation-based-inference_files/figure-revealjs/sample_mean_pois-1.png){fig-alt='Histogram showing the sampling distribution of the mean of 100 Poisson(1) variables with the peak centered around Xbar equal to 1.0.' width=960}\n:::\n:::\n\n\n\n## Simulating a sampling distribution\n\nBy the central limit theorem, all of these sampling distributions are asymptotically Gaussian with variance 1/100 (though the mean values differ between the three). Since $n=100$ is fairly large (for these examples), all of the previous examples are close to Gaussian.\n\nWhat about if $n$ is smaller? Or if we consider other distributions?\n\nSimulation is a powerful strategy for testing out methods:\n\n-   Suppose you wish to know... is $n$ large?\n-   Create a simulation that generates data that looks like your real world data.\n-   Evaluate whether the results are reasonable/accurate using simulated data.\n\n## Smaller sample sizes\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\nXbar_normal <- replicate(10000, mean(rnorm(10)))\nXbar_exp <- replicate(10000, mean(rexp(10, rate = 1)))\nXbar_poisson <- replicate(10000, mean(rpois(10, lambda = 1)))\npar(mfrow = c(1, 3))\nhist(Xbar_normal, main = \"N(0, 1)\")\nhist(Xbar_exp, main = \"Exp(1)\")\nhist(Xbar_poisson, main = \"Poisson(1)\")\n```\n:::\n\n\n\n## Smaller sample sizes\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](19_simulation-based-inference_files/figure-revealjs/smaller_sample2-1.png){fig-alt='Three side-by-side histograms showing normal, exponential, and Poisson distributions.' width=960}\n:::\n:::\n\n\n\n## Other statistics\n\nWhat if we want the sampling distribution of the maximum? For each of these population models, the sampling distribution of the maximum is different.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\nXmax_normal <- replicate(10000, max(rnorm(10)))\nXmax_exp <- replicate(10000, max(rexp(10, rate = 1)))\nXmax_poisson <- replicate(10000, max(rpois(10, lambda = 1)))\npar(mfrow = c(1, 3))\nhist(Xmax_normal, main = \"N(0, 1)\")\nhist(Xmax_exp, main = \"Exp(1)\")\nhist(Xmax_poisson, main = \"Poisson(1)\")\n```\n:::\n\n\n\n## Other statistics\n\nWhat if we want the sampling distribution of the maximum? For each of these population models, the sampling distribution of the maximum is different.\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](19_simulation-based-inference_files/figure-revealjs/max_sampling_dist2-1.png){fig-alt='Three histograms representing normal, exponential, and Poisson distributions.' width=960}\n:::\n:::\n\n\n\n## Transformations\n\nWe can easily simulate sampling distributions for statistics summarizing the distribution of random variables that are defined as transformations of other random variables.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\nXbar_normal <- replicate(10000, mean(rnorm(10) ^ 2))\nXbar_exp <- replicate(10000, mean(rexp(10, rate = 1) ^ 2))\nXbar_poisson <- replicate(10000, mean(rpois(10, lambda = 1) ^ 2))\npar(mfrow = c(1, 3))\nhist(Xbar_normal, main = \"N(0, 1) squared\")\nhist(Xbar_exp, main = \"Exp(1) squared\")\nhist(Xbar_poisson, main = \"Poisson(1) squared\")\n```\n:::\n\n\n\n## Transformations\n\nWe can easily simulate sampling distributions for statistics summarizing the distribution of random variables that are defined as transformations of other random variables.\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](19_simulation-based-inference_files/figure-revealjs/mean_transformed2-1.png){fig-alt='Three histograms showing the frequency distributions of squared values from normal, exponential, and Poisson distributions.' width=960}\n:::\n:::\n\n\n\n## Exercise\n\n-   Write code to create a histogram of the sampling distribution of the sample mean $\\overline{Y}$ of $Y_1,\\ldots, Y_{10}$ where $Y_i=\\sin(X_i)$ and $X_1,\\ldots, X_{10}$ are iid Uniform(0, 1) random variables.\n\n## Resampling methods\n\nThe previous simulations are all based on parametric models (normal, exponential, Poisson). However, we can also simulate sampling distributions without parametric assumptions on the data generating mechanism.\n\n## Estimating the age of US pennies\n\nSuppose we want to estimate the average age of US pennies. We can't observe every single penny---so what if we take a sample of 50 pennies?\n\n![](images/pennies.png){fig-alt=\"Two photographs: one of a busy street corner with pedestrians and a Florence Bank branch, and one of a hand holding a wrapper of fifty pennies.\"}\n\nBased on an example from [ModernDive](https://moderndive.com/8-confidence-intervals.html).\n\n## Estimating the age of US pennies\n\nThe `moderndive` package contains data on a sample of 50 pennies in the `pennies_sample` data frame.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(moderndive)\ndata(pennies_sample)\nhead(pennies_sample)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 2\n     ID  year\n  <int> <dbl>\n1     1  2002\n2     2  1986\n3     3  2017\n4     4  1988\n5     5  2008\n6     6  1983\n```\n\n\n:::\n:::\n\n\n\n## Estimating the age of US pennies\n\nThe `moderndive` package contains data on a sample of 50 pennies in the `pennies_sample` data frame.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nggplot(pennies_sample, aes(x = year)) +\n  geom_histogram(binwidth = 10, color = \"white\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](19_simulation-based-inference_files/figure-revealjs/pennies_2-1.png){fig-align='center' fig-alt='Bar chart showing counts for years 1970, 1990, 2000, 2010, and 2020. ' width=80%}\n:::\n:::\n\n\n\n## Estimating the age of US pennies\n\nBased on this sample, we can compute the sample mean:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nx_bar <- pennies_sample |>\n  summarize(mean_year = mean(year))\nx_bar\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 1\n  mean_year\n      <dbl>\n1     1995.\n```\n\n\n:::\n:::\n\n\n\n## Resampling the pennies\n\nImagine we put our 50 pennies in a bag and draw a **new** sample of 50 pennies by sampling with replacement. This is called **resampling with replacement.**\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(327)\npennies_resample <-\n  data.frame(year = sample(pennies$year, 50, replace = T))\nhead(pennies_resample)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  year\n1 1973\n2 1977\n3 1976\n4 2004\n5 1981\n6 2000\n```\n\n\n:::\n\n```{.r .cell-code}\npennies_resample %>% \n  summarize(mean_year = mean(year))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  mean_year\n1   1987.58\n```\n\n\n:::\n:::\n\n\n\n## Resampling the pennies {.smaller}\n\nImagine we put our 50 pennies in a bag and draw a **new** sample of 50 pennies by sampling with replacement. This is called **resampling with replacement.**\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npennies_combined <- \n  bind_rows(pennies_sample |> mutate(title = \"Original sample\"),\n            pennies_resample |> mutate(title = \"Resample\"))\nggplot(pennies_combined, aes(x = year)) +\n  geom_histogram(binwidth = 10, color = \"white\") +\n  facet_wrap(~title) + \n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](19_simulation-based-inference_files/figure-revealjs/pennies_5-1.png){fig-align='center' fig-alt='Two bar charts comparing \\'Original sample\\' and \\'Resample\\' data by year (1970, 1990, 2010). The y-axis is labeled \\'count,\\' and the x-axis is labeled \\'year.\\' ' width=100%}\n:::\n:::\n\n\n\n## Resampling the pennies\n\nNote that our resample is not the same as drawing a new sample from the population. However, we can still learn about the **sampling variability** of the sample mean. Suppose we repeat this process many times.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nhead(pennies_resamples)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 3\n# Groups:   name [1]\n  replicate name     year\n      <int> <chr>   <dbl>\n1         1 Arianna  1988\n2         1 Arianna  2002\n3         1 Arianna  2015\n4         1 Arianna  1998\n5         1 Arianna  1979\n6         1 Arianna  1971\n```\n\n\n:::\n:::\n\n\n\n## Resampling the pennies\n\nWe can compute each resample mean:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nresampled_means <- pennies_resamples |>\n  group_by(name) |>\n  summarize(mean_year = mean(year))\nhead(resampled_means)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 2\n  name      mean_year\n  <chr>         <dbl>\n1 Arianna       1992.\n2 Artemis       1996.\n3 Bea           1996.\n4 Camryn        1997.\n5 Cassandra     1991.\n6 Cindy         1995.\n```\n\n\n:::\n:::\n\n\n\n## Resampling the pennies\n\nWe can compute each resample mean:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(resampled_means, aes(x = mean_year)) +\n  geom_histogram(binwidth = 1, color = \"white\", boundary = 1990) +\n  labs(x = \"Sampled mean year\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](19_simulation-based-inference_files/figure-revealjs/pennies_8-1.png){fig-align='center' fig-alt='Bar chart showing count distribution over sampled years 1989, 1992, 1995, and 1998, with highest count of 8 in 1995.' width=100%}\n:::\n:::\n\n\n\n## Resampling the pennies 1000 times\n\nUsing simulation, we can repeat this process virtually 1000 times:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Repeat resampling 1000 times\nvirtual_resamples <- pennies_sample |>\n  rep_sample_n(size = 50, replace = TRUE, reps = 1000)\n\n# Compute 1000 sample means\nvirtual_resampled_means <- virtual_resamples |>\n  group_by(replicate) |>\n  summarize(mean_year = mean(year))\n```\n:::\n\n\n\n## Resampling the pennies 1000 times\n\nUsing simulation, we can repeat this process virtually 1000 times:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(virtual_resampled_means, aes(x = mean_year)) +\n  geom_histogram(binwidth = 1, color = \"white\", boundary = 1990) +\n  labs(x = \"sample mean\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](19_simulation-based-inference_files/figure-revealjs/pennies_10-1.png){fig-align='center' fig-alt='Bar graph showing a distribution with a peak around 1995.' width=100%}\n:::\n:::\n\n\n\n## Resampling the pennies 1000 times\n\nNote that our resampled means are centered around our original sample mean. This means that resampling doesn't tell us about how far off our particular sample is--only about the variability of the observed values.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nvirtual_resampled_means |>\n  summarize(mean_of_means = mean(mean_year))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 1\n  mean_of_means\n          <dbl>\n1         1995.\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(pennies_sample$year)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1995.44\n```\n\n\n:::\n:::\n\n\n\n## Resampling confidence intervals {.smaller}\n\nWe can obtain a confidence interval based on our resample means:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nquantile(virtual_resampled_means$mean_year, c(.025, .975))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    2.5%    97.5% \n1991.358 1999.441 \n```\n\n\n:::\n\n```{.r .cell-code}\nggplot(virtual_resampled_means, aes(x = mean_year)) +\n  geom_histogram(binwidth = 1, color = \"white\", boundary = 1990) +\n  geom_vline(xintercept = quantile(virtual_resampled_means$mean_year, c(.025, .975)), \n             color = 'red') +\n  labs(x = \"sample mean\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](19_simulation-based-inference_files/figure-revealjs/pennies_12-1.png){fig-align='center' fig-alt='Histogram showing the frequency distribution of sample means with vertical red lines marking 1990 and 2000.' width=100%}\n:::\n:::\n\n\n\n## Resampling confidence intervals\n\nCompare with a normal sampling distribution based confidence interval:\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nvirtual_resampled_means |>\n  summarize(lower = mean(mean_year) - 1.96 * sd(mean_year),\n            upper = mean(mean_year) + 1.96 * sd(mean_year))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 2\n  lower upper\n  <dbl> <dbl>\n1 1991. 2000.\n```\n\n\n:::\n:::\n\n\n\n## Resampling methods\n\nSuppose we know $X_1,\\ldots, X_{20}\\sim \\mathrm{Exp}(1)$. The sampling distribution of the sample mean can be simulated as follows:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\nXbar_exp <- replicate(10000, mean(rexp(20, rate = 1)))\nhist(Xbar_exp)\n```\n\n::: {.cell-output-display}\n![](19_simulation-based-inference_files/figure-revealjs/exp_samp_dist-1.png){fig-alt='Histogram of sampling distribution of mean of exponentials with red overlay for density' width=960}\n:::\n:::\n\n\n\n## Resampling methods\n\nWhat if we observe $X_1,\\ldots, X_{20}$, but we don't know that $X_i$ is exponentially distributed? We could just try the normal approximation to approximate the sampling distribution.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nX <- rexp(20, rate = 1)\nx_axis <- seq(0, 3, length.out = 1000)\n\n# plot \"true\" simulated sampling distribution\nhist(Xbar_exp, freq = F, ylim = c(0, 3))\n\n# plot normal theory\nlines(x_axis, dnorm(x_axis, mean = mean(X), sd = sd(X) / sqrt(20)), col = 'red')\n```\n:::\n\n\n\n## Resampling methods\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](19_simulation-based-inference_files/figure-revealjs/exp_samp_dist_22-1.png){fig-alt='Histogram of sampling distribution of mean of exponentials with red overlay for density' width=480}\n:::\n:::\n\n\n\n## Bootstrap samples\n\nBootstrapping is a resampling method that uses random samples with replacement from the sample data to approximate the sampling distribution of sample-based statistics.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprint(sort(X))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] 0.00816693 0.06263315 0.11949335 0.12600941 0.14474580 0.14660666\n [7] 0.15582213 0.17485277 0.23514296 0.35492087 0.48980207 0.52215538\n[13] 0.72200938 1.27034542 1.56551624 1.74866229 1.82459209 1.84311722\n[19] 2.14225230 2.24995288\n```\n\n\n:::\n\n```{.r .cell-code}\n# sample with replacement from X\nX_resample <- sample(X, size = 20, replace = TRUE)\nprint(sort(X_resample))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] 0.06263315 0.11949335 0.11949335 0.11949335 0.11949335 0.12600941\n [7] 0.14474580 0.14474580 0.15582213 0.15582213 0.17485277 0.35492087\n[13] 0.35492087 0.48980207 0.72200938 0.72200938 1.56551624 2.14225230\n[19] 2.24995288 2.24995288\n```\n\n\n:::\n:::\n\n\n\n## Bootstrap samples\n\nWe can repeatedly resample from $X$, then compute the resample sample means and plot the distribution:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbootstrap_Xbar <- replicate(10000, mean(sample(X, size = 20, replace = TRUE)))\nhist(bootstrap_Xbar - mean(X) + 1)\n```\n\n::: {.cell-output-display}\n![](19_simulation-based-inference_files/figure-revealjs/exp_samp_dist_4-1.png){fig-alt='Histogram of the bootstrap sample means' width=960}\n:::\n:::\n\n\n\n## Bootstrap samples\n\nWe can compare the bootstrap sampling distributions and true sampling distributions for $\\overline{X}-E(\\overline{X})$.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nplot_dat <-\n  data.frame(Xbar = c(Xbar_exp - 1, bootstrap_Xbar - mean(X)),\n             source = rep(c(\"Parametric (Exp)\", \"Bootstrap\"), each = 10000))\nggplot(plot_dat, aes(x = Xbar, color = source)) +\n  geom_density() +\n  geom_function(fun = dnorm, \n                args = list(mean = 0, sd = 1 / sqrt(20)),\n                aes(color = \"Parametric (Normal)\")) +\n  xlab(\"Xbar - E(Xbar)\")\n```\n:::\n\n\n\n## Bootstrap samples\n\nWe can compare the bootstrap sampling distributions and true sampling distributions for $\\overline{X}-E(\\overline{X})$.\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](19_simulation-based-inference_files/figure-revealjs/exp_samp_dist_52-1.png){fig-alt='Density plot of three sources: Bootstrap (red), Parametric (Exp) (green), and Parametric (Normal) (blue).' width=960}\n:::\n:::\n\n\n\n## Bootstrap confidence intervals\n\nWe can take appropriate quantiles of the bootstrap samples to construct a bootstrap confidence interval using the `quantile()` function:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nquantile(bootstrap_Xbar, probs = c(.025, .975))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    2.5%    97.5% \n0.467759 1.157051 \n```\n\n\n:::\n:::\n\n\n\n## Why bootstrap?\n\nIn this case, inference based on bootstrapping does not seem better than the normal approximation based on the central limit theorem.\n\nHowever, for many cases, we may not have a simple parametric approximation to the true sampling distribution. For example, suppose we wish to compute the sampling distribution of the sample median.\n\nNote however that the bootstrap may not work well for all statistics, such as the minimum (why not?).\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}